{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affective polarization analysis using FNES data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will output some CSV files, so set a path for where you'd like them to be saved. Also, set the path for the 2007, 2011, 2015 and 2019 data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = ''\n",
    "data_2007_path = ''\n",
    "data_2011_path = ''\n",
    "data_2015_path = ''\n",
    "data_2019_path = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've got data for four different years, and they're all a bit different, so let's get all of them together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2007 = pd.read_csv(data_2007_path, \n",
    "                        decimal = ',', delimiter = ';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column Q20B indicates whether the respondent feels at least somewhat close to a political party. The possible values are:\n",
    "\n",
    "* 1 (Centre Party of Finland)\n",
    "* 2 (Social Democratic Party of Finland)\n",
    "* 3 (National Coalition Party)\n",
    "* 4 (Left Alliance)\n",
    "* 5 (Green League)\n",
    "* 6 (Swedish People's Party in Finland)\n",
    "* 7 (Christian Democrats in Finland)\n",
    "* 8 (True Finns)\n",
    "* 9 (The Finnish Workers' Party)\n",
    "* 10 (The Independence Party)\n",
    "* 11 (Liberals)\n",
    "* 12 (Forces for Change in Finland)\n",
    "* 13 (For the Poor)\n",
    "* 14 (Joint Responsibility Party)\n",
    "* 15 (The Finnish Patriotic Movement)\n",
    "* 16 (Finnish People's Blue-Whites)\n",
    "* 17 (The Communist Party of Finland)\n",
    "* 18 (Finnish Senior Citizens' Party)\n",
    "* 19 (For Peace and Socialism-Communist Worker's Party)\n",
    "* 97 (Refused to say (SPONTANEOUS))\n",
    "* 98 (Can't say (SPONTANEOUS))\n",
    "* 99 Missing\n",
    "\n",
    "For the purposes of this analysis, because the survey only asks the respondents' opinions towars parliamentary parties, only those respondents who feel close to a parliamentary party are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "votes_2007 = [None, 23.11, 21.44, 22.26, 8.82, 8.46, 4.57, 4.86, 4.05]\n",
    "votes_2007_total = sum(votes_2007[1:])\n",
    "votes_2007 = [None] + [float(i) / votes_2007_total for i in votes_2007[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parties = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2007 = data_2007[data_2007['q20b'] < 9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions Q9A through Q9H contain the respondent's opinions on parliamentary parties. The order remains the same as in question Q20B, i.e. Q9A concerns the Centre Party, Q9B the Social Democratic Party, etc.\n",
    "\n",
    "Let's combine these into a single frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2011 = pd.read_csv(data_2011_path, decimal = ',',\n",
    "                        delimiter = ';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column Q20B indicates whether the respondent feels at least somewhat close to a political party. The possible values are:\n",
    "\n",
    "* 1 (Social Democratic Party of Finland)\n",
    "* 2 (Centre Party of Finland)\n",
    "* 3 (National Coalition Party)\n",
    "* 4 (Swedish People's Party in Finland)\n",
    "* 5 (Christian Democrats in Finland)\n",
    "* 6 (Green League)\n",
    "* 7 (Left Alliance)\n",
    "* 8 (True Finns)\n",
    "* 9 (The Communist Party of Finland)\n",
    "* 10 (Finnish Senior Citizens' Party)\n",
    "* 11 (For Peace and Socialism-Communist Worker's Party)\n",
    "* 12 (The Finnish Workers' Party)\n",
    "* 13 (The Independence Party)\n",
    "* 14 (For the Poor)\n",
    "* 15 (Pirate Party of Finland)\n",
    "* 16 (Change 2011)\n",
    "* 17 (Freedom Party)\n",
    "* 97 (Refused to say (SPONTANEOUS))\n",
    "* 98 (Can't say (SPONTANEOUS))\n",
    "* 99 Missing\n",
    "\n",
    "For the purposes of this analysis, because the survey only asks the respondents' opinions towars parliamentary parties, only those respondents who feel close to a parliamentary party are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "votes_2011 = [None, 19.10, 15.76, 20.38, 4.28, 4.03, 7.25, 8.13, 19.05]\n",
    "votes_2011_total = sum(votes_2011[1:])\n",
    "votes_2011 = [None] + [float(i) / votes_2011_total for i in votes_2011[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2011 = data_2011[data_2011['q20b'] < 9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab the respondents' opinions towards the parties. This time we again need to reorder them, so let's do it here so that the order matches the party affiliation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2015 = pd.read_csv(data_2015_path, \n",
    "                        delimiter = ';', decimal = ',', na_values = ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column Q16B indicates whether the respondent feels at least somewhat close to a political party. The possible values are:\n",
    "\n",
    "* 1 (National Coalition Party)\n",
    "* 2 (Social Democratic Party of Finland)\n",
    "* 3 (Finns Party)\n",
    "* 4 (Centre Party of Finland)\n",
    "* 5 (Left Alliance)\n",
    "* 6 (Green League)\n",
    "* 7 (Swedish People's Party in Finland)\n",
    "* 8 (Christian Democrats)\n",
    "* 9 (Pirate Party of Finland)\n",
    "* 10 (The Communist Party of Finland)\n",
    "* 11 (Change 2011)\n",
    "* 12 (Independence Party)\n",
    "* 13 (Worker's Party of Finland)\n",
    "* 14 (Communist Worker's Party)\n",
    "* 15 (For the Poor)\n",
    "* 97 (Don't want to say (SPONTANEOUS))\n",
    "* 98 (Can't say (SPONTANEOUS))\n",
    "\n",
    "For the purposes of this analysis, because the survey only asks the respondents' opinions towars parliamentary parties, only those respondents who feel close to a parliamentary party are included.\n",
    "\n",
    "Also, let's do some fixes because pandas loads the relevant columns as strings by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "votes_2015 = [None, 18.2, 16.5, 17.7, 21.1, 7.1, 8.5, 4.9, 3.5]\n",
    "votes_2015_total = sum(votes_2015[1:])\n",
    "votes_2015 = [None] + [float(i) / votes_2015_total for i in votes_2015[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2015 = data_2015[data_2015['q16b'] < 9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column Q22B contains a party number, if a respondent is a leaner.\n",
    "\n",
    "The possible values are:\n",
    "\n",
    "* 1 (Social Democratic Party of Finland)\n",
    "* 2 (National Coalition Party)\n",
    "* 3 (Finns Party)\n",
    "* 4 (Centre Party)\n",
    "* 5 (Green League)\n",
    "* 6 (Left Alliance)\n",
    "* 7 (Swedish People's Party in Finland)\n",
    "* 8 (Christian Democrats)\n",
    "* 9 (Blue Future)\n",
    "* 10 (Other)\n",
    "* 97 (Don't want to say)\n",
    "* 98 (Don't know)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2019 = pd.read_csv(data_2019_path, delimiter = ';', decimal = ',', na_values = ' ')\n",
    "data_2019 = data_2019[data_2019['Q22B'] < 9]\n",
    "votes_2019 = [None, 17.7, 17.0, 17.5, 13.8, 11.5, 8.2, 4.9, 3.5]\n",
    "votes_2019_total = sum(votes_2019[1:])\n",
    "votes_2019 = [None] + [float(i) / votes_2019_total for i in votes_2019[1:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grab opinions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opinions_2007 = data_2007[['q20b', 'q9a', 'q9b', 'q9c', 'q9d', 'q9e', 'q9f', 'q9g', 'q9h', 'painoki1']]\n",
    "opinions_2007.columns = ['own party'] + [i for i in range(1,9)] + ['weight']\n",
    "\n",
    "opinions_2007 = opinions_2007.replace([97, 98, 99], pd.np.nan)\n",
    "opinions_2007 = opinions_2007[pd.isna(opinions_2007).any(axis = 1) == False]\n",
    "\n",
    "opinions_2007 = opinions_2007.astype({'own party': 'int',\n",
    "                                      1: 'int',\n",
    "                                      2: 'int',\n",
    "                                      3: 'int',\n",
    "                                      4: 'int',\n",
    "                                      5: 'int',\n",
    "                                      6: 'int',\n",
    "                                      7: 'int',\n",
    "                                      8: 'int',\n",
    "                                      'weight': 'float'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opinions_2011 = data_2011[['q20b', 'q9c', 'q9a', 'q9b', 'q9f', 'q9g', 'q9e', 'q9d', 'q9h', 'painopu']]\n",
    "opinions_2011.columns = ['own party'] + [i for i in range(1,9)] + ['weight']\n",
    "\n",
    "opinions_2011 = opinions_2011.replace([97, 98, 99], pd.np.nan)\n",
    "opinions_2011 = opinions_2011[pd.isna(opinions_2011).any(axis = 1) == False]\n",
    "\n",
    "opinions_2011 = opinions_2011.astype({'own party': 'int',\n",
    "                                      1: 'int',\n",
    "                                      2: 'int',\n",
    "                                      3: 'int',\n",
    "                                      4: 'int',\n",
    "                                      5: 'int',\n",
    "                                      6: 'int',\n",
    "                                      7: 'int',\n",
    "                                      8: 'int',\n",
    "                                      'weight': 'float'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opinions_2015 = data_2015[['q16b', 'q9a', 'q9b', 'q9c', 'q9d', 'q9e', 'q9f', 'q9g', 'q9h', 'paino']]\n",
    "opinions_2015.columns = ['own party'] + [i for i in range(1,9)] + ['weight']\n",
    "\n",
    "opinions_2015 = opinions_2015.replace([96, 97, 98], pd.np.nan)\n",
    "opinions_2015 = opinions_2015[pd.isna(opinions_2015).any(axis = 1) == False]\n",
    "\n",
    "opinions_2015 = opinions_2015.astype({'own party': 'int',\n",
    "                                      1: 'int',\n",
    "                                      2: 'int',\n",
    "                                      3: 'int',\n",
    "                                      4: 'int',\n",
    "                                      5: 'int',\n",
    "                                      6: 'int',\n",
    "                                      7: 'int',\n",
    "                                      8: 'int',\n",
    "                                      'weight': 'float'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opinions_2019 = data_2019[['Q22B', 'Q015A', 'Q015B', 'Q015C', 'Q015D', 'Q015E', 'Q015F', 'Q015G', 'Q015H', 'paino']]\n",
    "opinions_2019.columns = ['own party'] + [i for i in range(1,9)] + ['weight']\n",
    "\n",
    "opinions_2019 = opinions_2019.replace([96, 97, 98], pd.np.nan)\n",
    "opinions_2019 = opinions_2019[pd.isna(opinions_2019).any(axis = 1) == False]\n",
    "\n",
    "opinions_2019 = opinions_2019.astype({'own party': 'int',\n",
    "                                      1: 'int',\n",
    "                                      2: 'int',\n",
    "                                      3: 'int',\n",
    "                                      4: 'int',\n",
    "                                      5: 'int',\n",
    "                                      6: 'int',\n",
    "                                      7: 'int',\n",
    "                                      8: 'int',\n",
    "                                      'weight': 'float'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup functions\n",
    "\n",
    "Not all of these are actually used. TODO: check out which ones are unnecessary and remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_API_for_data(data, votes):\n",
    "   data = data.groupby('own party')\n",
    "   data = data.mean().reset_index()\n",
    "   data = pd.concat([data, data.apply(compute_AP, votes = votes, axis = 1)], axis = 1)\n",
    "   data = pd.concat([data, data.apply(get_weights, votes = votes, axis = 1)], axis = 1)\n",
    "   data = pd.concat([data, data.apply(weigh_AP, votes = votes, axis = 1)], axis = 1)\n",
    "\n",
    "   API = data['weighted AP'].sum()\n",
    "    \n",
    "   return API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_AP(row, votes):\n",
    "    \n",
    "    ## The dataframe has a multi-index of the form (index, own party);\n",
    "    ## let's grab the respondent's own party from the second level \n",
    "    ## of the index.\n",
    "    \n",
    "    own = int(row['own party'])\n",
    "    like_own = row[own]\n",
    "    vote_own = votes[own]\n",
    "    \n",
    "    total_diff = 0\n",
    "    \n",
    "    for i in range(1, len(row)):\n",
    "        \n",
    "        if i == own:\n",
    "            \n",
    "            ## Check if the party we're comparing to is\n",
    "            ## the respondent's own party. Strictly speaking\n",
    "            ## this is not necessary, as the difference is always 0;\n",
    "            ## however, let's keep this for now just to be safe.\n",
    "            \n",
    "            continue\n",
    "        \n",
    "        like_other = row[i]\n",
    "        vote_other = votes[i]\n",
    "        \n",
    "        diff = (like_own - like_other) * (float(vote_other) / (1 - vote_own))\n",
    "        total_diff += diff\n",
    "        \n",
    "    return pd.Series(total_diff, index = ['AP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weigh_AP(row, votes):\n",
    "    \n",
    "    own = int(row['own party'])\n",
    "    AP = row['AP']\n",
    "    weighted_AP = AP * votes[own]\n",
    "    \n",
    "    return pd.Series(weighted_AP, index = ['weighted AP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(row, votes):\n",
    "    \n",
    "    own = int(row['own party'])\n",
    "    weight = votes[own]\n",
    "    \n",
    "    return pd.Series(weight, index = ['weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_API(row, votes):\n",
    "    \n",
    "    own = row.name\n",
    "    \n",
    "    return row[0] * votes[own]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_distance_matrix(row):\n",
    "    \n",
    "    own = int(row['own party'])\n",
    "    like_own = row[own]\n",
    "    \n",
    "    diffs = []\n",
    "    \n",
    "    for i in range(1, len(row)):\n",
    "        \n",
    "        like_other = row[i]\n",
    "        diff = like_own - like_other\n",
    "        diffs.append(diff)\n",
    "        \n",
    "    return pd.Series([int(own)] + diffs, index = ['own party'] + [i for i in range(1, len(row))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ingroup_score(row):\n",
    "    \n",
    "    own = row['own party']\n",
    "    like_own = row[own]\n",
    "    \n",
    "    return pd.Series([like_own], index = ['ingroup like'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outgroup_mean(row):\n",
    "    \n",
    "    own = row['own party']\n",
    "\n",
    "    outgroup_total = 0\n",
    "    \n",
    "    for i in range(1, len(row)):\n",
    "        \n",
    "        if i == own:\n",
    "            continue\n",
    "        \n",
    "        outgroup_total += row[i]\n",
    "        \n",
    "    outgroup_mean = outgroup_total / (len(row) - 2)\n",
    "    \n",
    "    return pd.Series([outgroup_mean], index = ['outgroup mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outgroup_minimum(row):\n",
    "    \n",
    "    own = row['own party']\n",
    "    \n",
    "    return min([row[i] for i in range(1, len(row)) if i != own])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outgroup_maximum(row):\n",
    "    \n",
    "    own = row['own party']\n",
    "    \n",
    "    return max([row[i] for i in range(1, len(row)) if i != own])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_and_percentiles(bootstrap_values, lower_bound, upper_bound):\n",
    "    \n",
    "    return ({'mean': np.mean(bootstrap_values), \n",
    "             'low': np.percentile(bootstrap_values, lower_bound), \n",
    "             'up': np.percentile(bootstrap_values, upper_bound)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_unweighted_polarization(row):\n",
    "    \n",
    "    own = int(row['own party'])\n",
    "    like_own = row[own]\n",
    "    \n",
    "    total_diff = 0\n",
    "    \n",
    "    for i in range(1, len(row)):\n",
    "        \n",
    "        if i == own:\n",
    "            \n",
    "            ## Check if the party we're comparing to is\n",
    "            ## the respondent's own party. Strictly speaking\n",
    "            ## this is not necessary, as the difference is always 0;\n",
    "            ## however, let's keep this for now just to be safe.\n",
    "            \n",
    "            continue\n",
    "        \n",
    "        like_other = row[i]\n",
    "        \n",
    "        diff = like_own - like_other\n",
    "        total_diff += diff\n",
    "        \n",
    "    return pd.Series(total_diff / (len(row) - 2), index = ['Unweighted polarization'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze indices and evaluations\n",
    "\n",
    "Compute several measures of affective polarization for each year:\n",
    "\n",
    "1. Reiljan's Affective Polarization Index\n",
    "2. Reiljan's Affective Polarization Index with survey weights\n",
    "3. Mean unweighted ingroup score\n",
    "4. Mean unweighted outgroup score\n",
    "5. Minimum unweighted outgroup score\n",
    "6. Maximum unweighted outgroup score\n",
    "7. Mean of all unweighted party scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_list = [votes_2007, votes_2011, votes_2015, votes_2019]\n",
    "data_list = [opinions_2007, opinions_2011, opinions_2015, opinions_2019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = []\n",
    "\n",
    "lower_bound = 1\n",
    "upper_bound = 100 - lower_bound\n",
    "\n",
    "seed = 12345\n",
    "np.random.seed(seed)\n",
    "\n",
    "for year_data, votes in zip(data_list, vote_list): \n",
    "\n",
    "    values = {}\n",
    "    \n",
    "    APIs = []\n",
    "    #weighted_APIs = []\n",
    "    mean_APs = []\n",
    "    #MAPs = []\n",
    "    in_means = []\n",
    "    out_means = []\n",
    "    out_mins = []\n",
    "    out_maxs = []\n",
    "    party_means = []\n",
    "    raw_polarizations = []\n",
    "    \n",
    "    for i in range(1, 1000):\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print('Running simulation ' + str(i))\n",
    "        \n",
    "        d = sklearn.utils.resample(year_data)\n",
    "        d = d.drop('weight', axis = 1)\n",
    "        APIs.append(compute_API_for_data(d, votes = votes))\n",
    "        mean_APs.append(d.apply(compute_AP, votes = votes, axis = 1).mean())\n",
    "        in_means.append(float(np.mean(d.apply(get_ingroup_score, axis = 1))))\n",
    "        out_means.append(float(np.mean(d.apply(get_outgroup_mean, axis = 1))))\n",
    "        out_mins.append(float(np.mean(d.apply(get_outgroup_minimum, axis = 1))))\n",
    "        out_maxs.append(float(np.mean(d.apply(get_outgroup_maximum, axis = 1))))\n",
    "        party_means.append(float(np.mean(d.drop('own party', axis = 1).mean(axis = 1))))\n",
    "        raw_polarizations.append(float(np.mean(d.apply(compute_unweighted_polarization, axis = 1).mean())))\n",
    "     \n",
    "    \n",
    "    values['api'] = get_mean_and_percentiles(APIs, lower_bound, upper_bound)\n",
    "    values['mean AP'] = get_mean_and_percentiles(mean_APs, lower_bound, upper_bound)\n",
    "    values['in_mean'] = get_mean_and_percentiles(in_means, lower_bound, upper_bound)\n",
    "    values['out_mean'] = get_mean_and_percentiles(out_means, lower_bound, upper_bound)\n",
    "    values['out_min'] = get_mean_and_percentiles(out_mins, lower_bound, upper_bound)\n",
    "    values['out_maxs'] = get_mean_and_percentiles(out_maxs, lower_bound, upper_bound)\n",
    "    values['party_means'] = get_mean_and_percentiles(party_means, lower_bound, upper_bound)\n",
    "    values['raw_polarizations'] = get_mean_and_percentiles(raw_polarizations, lower_bound, upper_bound)\n",
    "    \n",
    "    years.append(values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It might be a good idea to save the resulting object somewhere at this point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's build a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = [2007, 2011, 2015, 2019]\n",
    "\n",
    "api_df = pd.DataFrame(year['api'] for year in years)\n",
    "api_df['year'] = dates\n",
    "\n",
    "#w_api_df = pd.DataFrame(year['w_api'] for year in years)\n",
    "#w_api_df['year'] = dates\n",
    "\n",
    "ap_df = pd.DataFrame(year['mean AP'] for year in years)\n",
    "ap_df['year'] = dates\n",
    "\n",
    "#map_df = pd.DataFrame(year['map'] for year in years) * 10\n",
    "#map_df['year'] = dates\n",
    "\n",
    "in_mean_df = pd.DataFrame(year['in_mean'] for year in years)\n",
    "in_mean_df['year'] = dates\n",
    "\n",
    "out_mean_df = pd.DataFrame(year['out_mean'] for year in years)\n",
    "out_mean_df['year'] = dates\n",
    "\n",
    "out_maxs_df = pd.DataFrame(year['out_maxs'] for year in years)\n",
    "out_maxs_df['year'] = dates\n",
    "\n",
    "out_min_df = pd.DataFrame(year['out_min'] for year in years)\n",
    "out_min_df['year'] = dates\n",
    "\n",
    "party_mean_df = pd.DataFrame(year['party_means'] for year in years)\n",
    "party_mean_df['year'] = dates\n",
    "\n",
    "raw_polarizations_df = pd.DataFrame(year['raw_polarizations'] for year in years)\n",
    "raw_polarizations_df['year'] = dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_T = api_df.T\n",
    "api_T['attribute'] = 'API'\n",
    "#w_api_T = w_api_df.T \n",
    "#w_api_T['attribute'] = 'weighted_API'\n",
    "ap_df_T = ap_df.T \n",
    "ap_df_T['attribute'] = 'mean AP'\n",
    "in_mean_T = in_mean_df.T\n",
    "in_mean_T['attribute'] = 'inparty_mean'\n",
    "out_mean_T = out_mean_df.T\n",
    "out_mean_T['attribute'] = 'outparty_mean'\n",
    "out_maxs_T = out_maxs_df.T\n",
    "out_maxs_T['attribute'] = 'outparty_max'\n",
    "out_min_T = out_min_df.T\n",
    "out_min_T['attribute'] = 'outparty_min'\n",
    "party_mean_T = party_mean_df.T\n",
    "party_mean_T['attribute'] = 'party_mean'\n",
    "raw_polarizations_T = raw_polarizations_df.T\n",
    "raw_polarizations_T['attribute'] = 'raw_polarization'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df = pd.concat([api_T, ap_df_T, in_mean_T, out_mean_T, out_maxs_T, out_min_T, party_mean_T, \n",
    "           raw_polarizations_T])\n",
    "metric_df = metric_df.drop('year', axis = 0).reset_index()\n",
    "metric_df.columns = ['point', 2007, 2011, 2015, 2019, 'attribute']\n",
    "metric_df = metric_df[['attribute', 'point', 2007, 2011, 2015, 2019]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we can save this in a .CSV and move on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df.to_csv(output_path + '/API_tables2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze inter-party relationships\n",
    "\n",
    "Next, we'll build matrices Next we will build matrices of party ratings and inter-party distances and write them in .CSV files.\n",
    "\n",
    "The code contains tons of repetition (and thus possibilities for errors) and is *really* not very pretty, please forgive that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opinion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opinion_matrix_2007 = opinions_2007.groupby('own party').mean().reset_index()\n",
    "opinion_matrix_2007 = opinion_matrix_2007.drop(['own party', 'weight'], axis = 1)\n",
    "opinion_matrix_2007.columns = ['CPF', 'SDP', 'NCP', 'LA', 'GL', 'SPP', 'CD', 'FP']\n",
    "opinion_matrix_2007.index = ['CPF', 'SDP', 'NCP', 'LA', 'GL', 'SPP', 'CD', 'FP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opinion_matrix_2011 = opinions_2011.groupby('own party').mean().reset_index()\n",
    "opinion_matrix_2011 = opinion_matrix_2011.drop(['own party', 'weight'], axis = 1)\n",
    "opinion_matrix_2011.columns = ['SDP', 'CPF', 'NCP', 'SPP', 'CD', 'GL', 'LA', 'FP']\n",
    "opinion_matrix_2011.index = ['SDP', 'CPF', 'NCP', 'SPP', 'CD', 'GL', 'LA', 'FP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opinion_matrix_2015 = opinions_2015.groupby('own party').mean().reset_index()\n",
    "opinion_matrix_2015 = opinion_matrix_2015.drop(['own party', 'weight'], axis = 1)\n",
    "opinion_matrix_2015.columns = ['NCP', 'SDP', 'FP', 'CPF', 'LA', 'GL', 'SPP', 'CD']\n",
    "opinion_matrix_2015.index = ['NCP', 'SDP', 'FP', 'CPF', 'LA', 'GL', 'SPP', 'CD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opinion_matrix_2019 = opinions_2019.groupby('own party').mean().reset_index()\n",
    "opinion_matrix_2019 = opinion_matrix_2019.drop(['own party', 'weight'], axis = 1)\n",
    "opinion_matrix_2019.columns = ['SDP', 'NCP', 'FP', 'CPF', 'GL', 'LA', 'SPP', 'CD']\n",
    "opinion_matrix_2019.index = ['SDP', 'NCP', 'FP', 'CPF', 'GL', 'LA', 'SPP', 'CD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opinion_matrix_2007 = opinion_matrix_2007.sort_index(0)\n",
    "opinion_matrix_2007 = opinion_matrix_2007.sort_index(1)\n",
    "opinion_matrix_2011 = opinion_matrix_2011.sort_index(0)\n",
    "opinion_matrix_2011 = opinion_matrix_2011.sort_index(1)\n",
    "opinion_matrix_2015 = opinion_matrix_2015.sort_index(0)\n",
    "opinion_matrix_2015 = opinion_matrix_2015.sort_index(1)\n",
    "opinion_matrix_2019 = opinion_matrix_2019.sort_index(0)\n",
    "opinion_matrix_2019 = opinion_matrix_2019.sort_index(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opinion_matrix_2007.to_csv(output_path + 'opinions_2007.csv')\n",
    "opinion_matrix_2011.to_csv(output_path + 'opinions_2011.csv')\n",
    "opinion_matrix_2015.to_csv(output_path + 'opinions_2015.csv')\n",
    "opinion_matrix_2019.to_csv(output_path + 'opinions_2019.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AP (inter-party distance) matrices\n",
    "\n",
    "1. Group respondents by group\n",
    "2. Get mean like scores for each party $L_i$ for $i \\ldots n$\n",
    "3. Compute $L_O - L_i$ for each $i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix_2007 = opinions_2007.groupby('own party').mean().reset_index().drop('weight', axis = 1).apply(create_distance_matrix, axis = 1)\n",
    "distance_matrix_2007 = distance_matrix_2007.drop('own party', axis = 1)\n",
    "distance_matrix_2007.columns = ['CPF', 'SDP', 'NCP', 'LA', 'GL', 'SPP', 'CD', 'FP']\n",
    "distance_matrix_2007.index = ['CPF', 'SDP', 'NCP', 'LA', 'GL', 'SPP', 'CD', 'FP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix_2011 = opinions_2011.groupby('own party').mean().reset_index().drop('weight', axis = 1).apply(create_distance_matrix, axis = 1)\n",
    "distance_matrix_2011 = distance_matrix_2011.drop('own party', axis = 1)\n",
    "distance_matrix_2011.columns = ['SDP', 'CPF', 'NCP', 'SPP', 'CD', 'GL', 'LA', 'FP']\n",
    "distance_matrix_2011.index = ['SDP', 'CPF', 'NCP', 'SPP', 'CD', 'GL', 'LA', 'FP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix_2015 = opinions_2015.groupby('own party').mean().reset_index().drop('weight', axis = 1).apply(create_distance_matrix, axis = 1)\n",
    "distance_matrix_2015 = distance_matrix_2015.drop('own party', axis = 1)\n",
    "distance_matrix_2015.columns = ['NCP', 'SDP', 'FP', 'CPF', 'LA', 'GL', 'SPP', 'CD']\n",
    "distance_matrix_2015.index = ['NCP', 'SDP', 'FP', 'CPF', 'LA', 'GL', 'SPP', 'CD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix_2019 = opinions_2019.groupby('own party').mean().reset_index().drop('weight', axis = 1).apply(create_distance_matrix, axis = 1)\n",
    "distance_matrix_2019 = distance_matrix_2019.drop('own party', axis = 1)\n",
    "distance_matrix_2019.columns = ['SDP', 'NCP', 'FP', 'CPF', 'GL', 'LA', 'SPP', 'CD']\n",
    "distance_matrix_2019.index = ['SDP', 'NCP', 'FP', 'CPF', 'GL', 'LA', 'SPP', 'CD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix_2007 = distance_matrix_2007.reindex(['CD', 'NCP', 'CPF', 'FP', 'SPP', 'SDP', 'LA', 'GL'], axis = 0)\n",
    "distance_matrix_2007 = distance_matrix_2007.reindex(['CD', 'NCP', 'CPF', 'FP', 'SPP', 'SDP', 'LA', 'GL'], axis = 1)\n",
    "distance_matrix_2011 = distance_matrix_2011.reindex(['CD', 'NCP', 'CPF', 'FP', 'SPP', 'SDP', 'LA', 'GL'], axis = 0)\n",
    "distance_matrix_2011 = distance_matrix_2011.reindex(['CD', 'NCP', 'CPF', 'FP', 'SPP', 'SDP', 'LA', 'GL'], axis = 1)\n",
    "distance_matrix_2015 = distance_matrix_2015.reindex(['CD', 'NCP', 'CPF', 'FP', 'SPP', 'SDP', 'LA', 'GL'], axis = 0)\n",
    "distance_matrix_2015 = distance_matrix_2015.reindex(['CD', 'NCP', 'CPF', 'FP', 'SPP', 'SDP', 'LA', 'GL'], axis = 1)\n",
    "distance_matrix_2019 = distance_matrix_2019.reindex(['CD', 'NCP', 'CPF', 'FP', 'SPP', 'SDP', 'LA', 'GL'], axis = 0)\n",
    "distance_matrix_2019 = distance_matrix_2019.reindex(['CD', 'NCP', 'CPF', 'FP', 'SPP', 'SDP', 'LA', 'GL'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix_2007 = distance_matrix_2007.sort_index(0)\n",
    "distance_matrix_2007 = distance_matrix_2007.sort_index(1)\n",
    "distance_matrix_2011 = distance_matrix_2011.sort_index(0)\n",
    "distance_matrix_2011 = distance_matrix_2011.sort_index(1)\n",
    "distance_matrix_2015 = distance_matrix_2015.sort_index(0)\n",
    "distance_matrix_2015 = distance_matrix_2015.sort_index(1)\n",
    "distance_matrix_2019 = distance_matrix_2019.sort_index(0)\n",
    "distance_matrix_2019 = distance_matrix_2019.sort_index(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix_2007.to_csv(output_path + 'distances_2007.csv')\n",
    "distance_matrix_2011.to_csv(output_path + 'distances_2011.csv')\n",
    "distance_matrix_2015.to_csv(output_path + 'distances_2015.csv')\n",
    "distance_matrix_2019.to_csv(output_path + 'distances_2019.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
